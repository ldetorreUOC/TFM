{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# 1. Preprocesamiento del conjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:29:54.646289Z",
     "iopub.status.busy": "2023-06-05T17:29:54.645884Z",
     "iopub.status.idle": "2023-06-05T17:29:56.574705Z",
     "shell.execute_reply": "2023-06-05T17:29:56.573255Z",
     "shell.execute_reply.started": "2023-06-05T17:29:54.646250Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Cargamos el fichero en rows\n",
    "rows = []\n",
    "with open(\"/kaggle/input/lorawan-files/lorawan_dataset_antwerp.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile,)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:29:56.577913Z",
     "iopub.status.busy": "2023-06-05T17:29:56.577512Z",
     "iopub.status.idle": "2023-06-05T17:29:56.584177Z",
     "shell.execute_reply": "2023-06-05T17:29:56.582362Z",
     "shell.execute_reply.started": "2023-06-05T17:29:56.577879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializamos las variables\n",
    "devices_pos = []\n",
    "devices_rssi_from_gateways = []\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:29:56.587494Z",
     "iopub.status.busy": "2023-06-05T17:29:56.585724Z",
     "iopub.status.idle": "2023-06-05T17:30:19.740829Z",
     "shell.execute_reply": "2023-06-05T17:30:19.739189Z",
     "shell.execute_reply.started": "2023-06-05T17:29:56.587444Z"
    }
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "for elem in rows:\n",
    "    aux_rssi = np.asarray(deepcopy(elem[:-5]), dtype=int)\n",
    "    devices_rssi_from_gateways.append(aux_rssi.tolist())\n",
    "\n",
    "    get_date_obj_ = parse(deepcopy(elem[-5]))\n",
    "    times.append(deepcopy(int(get_date_obj_.timestamp()*1000)))\n",
    "\n",
    "\n",
    "    aux_pos = np.asarray(deepcopy(elem[-2:]), dtype=float)\n",
    "    devices_pos.append([aux_pos[0],aux_pos[1]])\n",
    "\n",
    "    \n",
    "# Ordenamos cronológicamente\n",
    "devices_pos_sorted = [x for _, x in sorted(zip(times, devices_pos))]\n",
    "devices_rssi_from_gateways_sorted = [x for _, x in sorted(zip(times, devices_rssi_from_gateways))]\n",
    "times_sorted = [x for _, x in sorted(zip(times, times))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:19.743959Z",
     "iopub.status.busy": "2023-06-05T17:30:19.743591Z",
     "iopub.status.idle": "2023-06-05T17:30:19.762881Z",
     "shell.execute_reply": "2023-06-05T17:30:19.761634Z",
     "shell.execute_reply.started": "2023-06-05T17:30:19.743926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparamos la división del conjuto en train (80%) y test (20%)\n",
    "# de forma cronológica\n",
    "test_index = [False] * len(devices_pos_sorted)\n",
    "train_size = int(len(devices_pos_sorted) * 0.8)\n",
    "\n",
    "for i in range(len(devices_pos_sorted)):\n",
    "  if i > train_size:\n",
    "    test_index[i] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:19.764802Z",
     "iopub.status.busy": "2023-06-05T17:30:19.764431Z",
     "iopub.status.idle": "2023-06-05T17:30:19.858497Z",
     "shell.execute_reply": "2023-06-05T17:30:19.856895Z",
     "shell.execute_reply.started": "2023-06-05T17:30:19.764772Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos los conjuntois de train y de test\n",
    "train_X = []\n",
    "test_X = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(len(devices_pos_sorted)):\n",
    "  if test_index[i]:\n",
    "    test_X.append(devices_rssi_from_gateways_sorted[i])\n",
    "    test_y.append(devices_pos_sorted[i])\n",
    "  else:\n",
    "    train_X.append(devices_rssi_from_gateways_sorted[i])\n",
    "    train_y.append(devices_pos_sorted[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:19.860615Z",
     "iopub.status.busy": "2023-06-05T17:30:19.860286Z",
     "iopub.status.idle": "2023-06-05T17:30:20.613141Z",
     "shell.execute_reply": "2023-06-05T17:30:20.611594Z",
     "shell.execute_reply.started": "2023-06-05T17:30:19.860585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos la función de Haversine\n",
    "# Permite hallar la distancia en metros entre dos puntos de la tierra dada su latitud y longitud\n",
    "import geopy.distance\n",
    "import math\n",
    "\n",
    "def haversine(lat1, lat2, lon1, lon2):\n",
    "    return geopy.distance.geodesic((lat1, lon1), (lat2, lon2)).km * 1000\n",
    "\n",
    "# Definimos una función propia de KNN\n",
    "# Permite hacer KNN considerando únicamente vecinos concretos y no todos los vecinos\n",
    "from scipy.spatial import distance\n",
    "def knn_algorithm(k, train_X, test_X, train_y, test_y, considered_index = [], distancia = 'euclidea'):\n",
    "    min_distances = []\n",
    "    min_distances_index = []\n",
    "    \n",
    "    # Recorremos cada elemento de test\n",
    "    for i in range(len(test_X)):\n",
    "        min_distances.append([])\n",
    "        min_distances_index.append([])\n",
    "        # Recorremos cada elemento de train que consideramos\n",
    "        if considered_index != []:\n",
    "            index_to_consider = considered_index[i]\n",
    "        else:\n",
    "            index_to_consider = range(len(train_X))\n",
    "        for j in index_to_consider:\n",
    "            # Seleccionamos la métrica para medir la distancia entre vecinos\n",
    "            if distancia == 'sorensen':\n",
    "                current_distance = sorensen_distance(train_X[j], test_X[i])\n",
    "            elif distancia == 'manhattan':\n",
    "                current_distance = cityblock(train_X[j], test_X[i])\n",
    "            else: # distancia euclidea\n",
    "                current_distance = math.dist(train_X[j], test_X[i])\n",
    "            if len(min_distances[-1]) < k:\n",
    "                min_distances[-1].append(current_distance)\n",
    "                min_distances_index[-1].append(j)\n",
    "                min_distances_index[-1] = [x for _, x in sorted(zip(min_distances[-1], min_distances_index[-1]))]\n",
    "                min_distances[-1].sort()\n",
    "\n",
    "            elif min_distances[-1][-1] > current_distance:\n",
    "                min_distances[-1][-1] = current_distance\n",
    "                min_distances_index[-1][-1] = j\n",
    "                min_distances_index[-1] = [x for _, x in sorted(zip(min_distances[-1], min_distances_index[-1]))]\n",
    "                min_distances[-1].sort()\n",
    "                \n",
    "    predict_y = []\n",
    "\n",
    "    # Hallamos las predicciones del conjunto de test\n",
    "    for i in range(len(min_distances_index)):\n",
    "        punto = [0.0,0.0]\n",
    "        for j in min_distances_index[i]:\n",
    "            punto[0] += train_y[j][0]\n",
    "            punto[1] += train_y[j][1]\n",
    "        num_elems = len(min_distances_index[i])\n",
    "        punto[0] =1.0*punto[0]/(1.0*num_elems)\n",
    "        punto[1] =1.0*punto[1]/(1.0*num_elems)\n",
    "        predict_y.append(deepcopy(punto))\n",
    "        \n",
    "    distances_test_predict = []\n",
    "    for i in range(len(predict_y)):\n",
    "        distances_test_predict.append(haversine(test_y[i][0],predict_y[i][0],test_y[i][1],predict_y[i][1]))\n",
    "        \n",
    "    # Calculamos el error medio\n",
    "    mean_error = np.mean(distances_test_predict)\n",
    "    mean_error\n",
    "            \n",
    "    return predict_y, mean_error, min_distances_index, min_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:20.615258Z",
     "iopub.status.busy": "2023-06-05T17:30:20.614633Z",
     "iopub.status.idle": "2023-06-05T17:30:20.625914Z",
     "shell.execute_reply": "2023-06-05T17:30:20.624440Z",
     "shell.execute_reply.started": "2023-06-05T17:30:20.615226Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_multiple_KNN_with_min_distances_and_index(ks, min_distances_index, train_y, test_y):\n",
    "    predicted_ys = []\n",
    "    mean_errors = []\n",
    "    for k in ks:\n",
    "        predict_y = []\n",
    "        for i in range(min(len(min_distances_index), k)):\n",
    "            punto = [0.0,0.0]\n",
    "            for j in min_distances_index[i]:\n",
    "                punto[0] += train_y[j][0]\n",
    "                punto[1] += train_y[j][1]\n",
    "            num_elems = len(min_distances_index[i])\n",
    "            punto[0] =1.0*punto[0]/(1.0*num_elems)\n",
    "            punto[1] =1.0*punto[1]/(1.0*num_elems)\n",
    "            predict_y.append(deepcopy(punto))\n",
    "\n",
    "        distances_test_predict = []\n",
    "        for i in range(len(predict_y)):\n",
    "            distances_test_predict.append(haversine(test_y[i][0],predict_y[i][0],test_y[i][1],predict_y[i][1]))\n",
    "\n",
    "        # Calculamos el error medio\n",
    "        mean_error = np.mean(distances_test_predict)\n",
    "        mean_error\n",
    "\n",
    "        predicted_ys.append(predict_y)\n",
    "        mean_errors.append(mean_error)\n",
    "        print(\"Para KNN con k = \" + str(k) + \" el error medio es \" + str(mean_error) + \" metros.\")\n",
    "    return predicted_ys, mean_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.549674Z",
     "iopub.status.idle": "2023-05-31T21:22:29.550746Z",
     "shell.execute_reply": "2023-05-31T21:22:29.550472Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.550444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos KNN con K = 15 y guardamos las distancias para poder hallarlo para k < 15\n",
    "import time\n",
    "k = 15\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "min_distances_index = []\n",
    "min_distances = []\n",
    "start = time.time()\n",
    "predict_y, mean_error,min_distances_index,min_distances = knn_algorithm(k, train_X, test_X, train_y, test_y)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo de ejecución del KNN = \" + str(end-start))\n",
    "\n",
    "# Con los valores obtenidos, calculamos el error medio de KNN para K de 1 a 15\n",
    "ks = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "predicted_ys, mean_errors = get_multiple_KNN_with_min_distances_and_index(ks, min_distances_index, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.552227Z",
     "iopub.status.idle": "2023-05-31T21:22:29.553312Z",
     "shell.execute_reply": "2023-05-31T21:22:29.553067Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.553041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos en ficheros los valores predichos, los errores medios, las distancias mínimas \n",
    "# y los índices del conjuntio de train de las distancias mínimas\n",
    "import pickle\n",
    "\n",
    "KNN_15_predicted_y = open('KNN_15_predicted_y.obj', 'wb')\n",
    "pickle.dump(predicted_ys, KNN_15_predicted_y)\n",
    "KNN_15_predicted_y.close()\n",
    "\n",
    "KNN_15_mean_error = open('KNN_15_mean_errors.obj', 'wb')\n",
    "pickle.dump(mean_errors, KNN_15_mean_error)\n",
    "KNN_15_mean_error.close()\n",
    "\n",
    "KNN_15_min_index = open('KNN_15_min_index.obj', 'wb')\n",
    "pickle.dump(min_distances_index, KNN_15_min_index)\n",
    "KNN_15_min_index.close()\n",
    "\n",
    "KNN_15_min_dist = open('KNN_15_min_dist.obj', 'wb')\n",
    "pickle.dump(min_distances, KNN_15_min_dist)\n",
    "KNN_15_min_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:20.630245Z",
     "iopub.status.busy": "2023-06-05T17:30:20.628106Z",
     "iopub.status.idle": "2023-06-05T17:30:20.649229Z",
     "shell.execute_reply": "2023-06-05T17:30:20.648130Z",
     "shell.execute_reply.started": "2023-06-05T17:30:20.630199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para KNN con k = 1 el error medio es 432.02246622317 metros.\n",
      "Para KNN con k = 2 el error medio es 293.41521187256456 metros.\n",
      "Para KNN con k = 3 el error medio es 245.46220217655608 metros.\n",
      "Para KNN con k = 4 el error medio es 288.46604348731864 metros.\n",
      "Para KNN con k = 5 el error medio es 315.953085641042 metros.\n",
      "Para KNN con k = 6 el error medio es 311.0387996409501 metros.\n",
      "Para KNN con k = 7 el error medio es 329.4350314310435 metros.\n",
      "Para KNN con k = 8 el error medio es 346.7588407609875 metros.\n",
      "Para KNN con k = 9 el error medio es 325.96238469145277 metros.\n",
      "Para KNN con k = 10 el error medio es 365.96681832473485 metros.\n",
      "Para KNN con k = 11 el error medio es 364.45502217886445 metros.\n",
      "Para KNN con k = 12 el error medio es 349.5102156154953 metros.\n",
      "Para KNN con k = 13 el error medio es 362.4640369187582 metros.\n",
      "Para KNN con k = 14 el error medio es 355.1635881188382 metros.\n",
      "Para KNN con k = 15 el error medio es 350.6831811179458 metros.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "KNN_15_mean_error = open('/kaggle/input/lorawan-output/KNN_15_mean_errors.obj', 'rb') \n",
    "mean_errors = pickle.load(KNN_15_mean_error)\n",
    "KNN_15_mean_error.close()\n",
    "\n",
    "for i in range(len(mean_errors)):\n",
    "    print(\"Para KNN con k = \" + str(i+1) + \" el error medio es \" + str(mean_errors[i]) + \" metros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Uso de índices para optimizar: Todos coincidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.557035Z",
     "iopub.status.idle": "2023-05-31T21:22:29.557558Z",
     "shell.execute_reply": "2023-05-31T21:22:29.557315Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.557289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos los índices del conjunto de train con rssi != -200\n",
    "train_indexes_rssi = []\n",
    "\n",
    "for i in range(len(train_X)):\n",
    "    train_indexes_rssi.append([])\n",
    "    for j in range(len(train_X[i])):\n",
    "        if train_X[i][j] != -200:\n",
    "            train_indexes_rssi[i].append(j)\n",
    "            \n",
    "# Calculamos, para cada elemento de test, los índices del conjunto de train\n",
    "# que tienen señal en exactamente los mismos índices que el elemento de test\n",
    "considered_index = []\n",
    "l = 1\n",
    "for test_elem in test_X:\n",
    "    considered_index.append([])\n",
    "    current_indexes = []\n",
    "    for i in range(len(test_elem)):\n",
    "        if test_elem[i] != -200:\n",
    "            current_indexes.append(i)\n",
    "    \n",
    "    for j in range(len(train_X)):\n",
    "        if len(train_indexes_rssi[j]) == len(current_indexes):\n",
    "            n = 0\n",
    "            for i in current_indexes:\n",
    "                if train_X[j][i] != -200:\n",
    "                    n+=1\n",
    "            if n == len(current_indexes):\n",
    "                considered_index[-1].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.559950Z",
     "iopub.status.idle": "2023-05-31T21:22:29.560731Z",
     "shell.execute_reply": "2023-05-31T21:22:29.560449Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.560422Z"
    }
   },
   "outputs": [],
   "source": [
    "KNN_test_index_todos_coincidentes = open('KNN_test_index_todos_coincidentes.obj', 'wb')\n",
    "pickle.dump(considered_index, KNN_test_index_todos_coincidentes)\n",
    "KNN_test_index_todos_coincidentes.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.562606Z",
     "iopub.status.idle": "2023-05-31T21:22:29.563588Z",
     "shell.execute_reply": "2023-05-31T21:22:29.563315Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.563286Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(considered_index))\n",
    "n = 0\n",
    "for elem in considered_index:\n",
    "    if elem == []:\n",
    "        n += 1\n",
    "print(\"Hay \" + str(n) + \" elementos del conjunto de test para los que no existe nigún elemento de train con señal en exactamente los mismos índices\")\n",
    "\n",
    "# Creamos las nuevas variables de test para este caso, eliminando aquellso que no consideramos\n",
    "test_X_todos_coincidentes = [x for x, y in zip(test_X, considered_index) if y != []]\n",
    "test_y_todos_coincidentes = [x for x, y in zip(test_y, considered_index) if y != []]\n",
    "considered_index_todos_coincidentes = [x for x in considered_index if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.566006Z",
     "iopub.status.idle": "2023-05-31T21:22:29.567128Z",
     "shell.execute_reply": "2023-05-31T21:22:29.566860Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.566830Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos KNN con K = 15 y guardamos las distancias para poder hallarlo para k < 15\n",
    "import time\n",
    "k = 15\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "min_distances_index = []\n",
    "min_distances = []\n",
    "start = time.time()\n",
    "predict_y, mean_error,min_distances_index,min_distances = knn_algorithm(k, train_X, test_X_todos_coincidentes, train_y, test_y_todos_coincidentes,considered_index_todos_coincidentes)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo de ejecución del KNN con todos los índices coincidentes = \" + str(end-start))\n",
    "\n",
    "# Con los valores obtenidos, calculamos el error medio de KNN para K de 1 a 15\n",
    "ks = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "predicted_ys, mean_errors = get_multiple_KNN_with_min_distances_and_index(ks, min_distances_index, train_y, test_y_todos_coincidentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.569088Z",
     "iopub.status.idle": "2023-05-31T21:22:29.570220Z",
     "shell.execute_reply": "2023-05-31T21:22:29.569976Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.569949Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos en ficheros los valores predichos, los errores medios, las distancias mínimas \n",
    "# y los índices del conjuntio de train de las distancias mínimas\n",
    "KNN_15_todos_coincidentes_predicted_y = open('KNN_15_todos_coincidentes_predicted_y.obj', 'wb')\n",
    "pickle.dump(predicted_ys, KNN_15_todos_coincidentes_predicted_y)\n",
    "KNN_15_todos_coincidentes_predicted_y.close()\n",
    "\n",
    "KNN_15_todos_coincidentes_mean_error = open('KNN_15_todos_coincidentes_mean_error.obj', 'wb')\n",
    "pickle.dump(mean_errors, KNN_15_todos_coincidentes_mean_error)\n",
    "KNN_15_todos_coincidentes_mean_error.close()\n",
    "\n",
    "KNN_15_todos_coincidentes_min_index = open('KNN_15_todos_coincidentes_min_index.obj', 'wb')\n",
    "pickle.dump(min_distances_index, KNN_15_todos_coincidentes_min_index)\n",
    "KNN_15_todos_coincidentes_min_index.close()\n",
    "\n",
    "KNN_15_todos_coincidentes_min_dist = open('KNN_15_todos_coincidentes_min_dist.obj', 'wb')\n",
    "pickle.dump(min_distances, KNN_15_todos_coincidentes_min_dist)\n",
    "KNN_15_todos_coincidentes_min_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:20.651461Z",
     "iopub.status.busy": "2023-06-05T17:30:20.650672Z",
     "iopub.status.idle": "2023-06-05T17:30:20.665853Z",
     "shell.execute_reply": "2023-06-05T17:30:20.664722Z",
     "shell.execute_reply.started": "2023-06-05T17:30:20.651430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para KNN con k = 1 el error medio es 439.95789747402347 metros.\n",
      "Para KNN con k = 2 el error medio es 297.38292749799126 metros.\n",
      "Para KNN con k = 3 el error medio es 248.10734592684057 metros.\n",
      "Para KNN con k = 4 el error medio es 290.44990130003197 metros.\n",
      "Para KNN con k = 5 el error medio es 317.5401718912126 metros.\n",
      "Para KNN con k = 6 el error medio es 312.36137151609233 metros.\n",
      "Para KNN con k = 7 el error medio es 330.5686644668796 metros.\n",
      "Para KNN con k = 8 el error medio es 347.7507696673441 metros.\n",
      "Para KNN con k = 9 el error medio es 326.8440992748809 metros.\n",
      "Para KNN con k = 10 el error medio es 366.76036144982015 metros.\n",
      "Para KNN con k = 11 el error medio es 365.1764250198511 metros.\n",
      "Para KNN con k = 12 el error medio es 350.40849969206596 metros.\n",
      "Para KNN con k = 13 el error medio es 363.293222220208 metros.\n",
      "Para KNN con k = 14 el error medio es 355.9335458987559 metros.\n",
      "Para KNN con k = 15 el error medio es 351.40180837920235 metros.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "KNN_15_todos_coincidentes_mean_error = open('/kaggle/input/lorawan-output/KNN_15_todos_coincidentes_mean_error.obj', 'rb') \n",
    "mean_errors = pickle.load(KNN_15_todos_coincidentes_mean_error)\n",
    "KNN_15_todos_coincidentes_mean_error.close()\n",
    "\n",
    "for i in range(len(mean_errors)):\n",
    "    print(\"Para KNN con k = \" + str(i+1) + \" el error medio es \" + str(mean_errors[i]) + \" metros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Uso de índices para optimizar: Al menos 3 coincidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.575627Z",
     "iopub.status.idle": "2023-05-31T21:22:29.576474Z",
     "shell.execute_reply": "2023-05-31T21:22:29.576208Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.576177Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_considered_index_at_least_m_equal(m, train_X, test_X):\n",
    "    considered_index = []\n",
    "    for test_elem in test_X:\n",
    "        considered_index.append([])\n",
    "        current_indexes = []\n",
    "        for i in range(len(test_elem)):\n",
    "            if test_elem[i] != -200:\n",
    "                current_indexes.append(i)\n",
    "\n",
    "        for j in range(len(train_X)):\n",
    "            n = 0\n",
    "            for i in current_indexes:\n",
    "                if train_X[j][i] != -200:\n",
    "                    n+=1\n",
    "                    if n >= m:\n",
    "                        considered_index[-1].append(j)\n",
    "                        break\n",
    "    return considered_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.577887Z",
     "iopub.status.idle": "2023-05-31T21:22:29.578424Z",
     "shell.execute_reply": "2023-05-31T21:22:29.578185Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.578158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos, para cada elemento de test, los índices del conjunto de train\n",
    "# que tienen señal en exactamente los mismos índices que el elemento de test\n",
    "considered_index = []\n",
    "considered_index = get_considered_index_at_least_m_equal(3, train_X, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.579886Z",
     "iopub.status.idle": "2023-05-31T21:22:29.580642Z",
     "shell.execute_reply": "2023-05-31T21:22:29.580367Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.580339Z"
    }
   },
   "outputs": [],
   "source": [
    "KNN_test_index_tres_coincidentes = open('KNN_test_index_tres_coincidentes.obj', 'wb')\n",
    "pickle.dump(considered_index, KNN_test_index_tres_coincidentes)\n",
    "KNN_test_index_tres_coincidentes.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.582294Z",
     "iopub.status.idle": "2023-05-31T21:22:29.582862Z",
     "shell.execute_reply": "2023-05-31T21:22:29.582607Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.582580Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(considered_index))\n",
    "n = 0\n",
    "for elem in considered_index:\n",
    "    if elem == []:\n",
    "        n += 1\n",
    "print(\"Hay \" + str(n) + \" elementos del conjunto de test para los que no existe nigún elemento de train con señal en al menos tres mismos índices\")\n",
    "\n",
    "# Creamos las nuevas variables de test para este caso, eliminando aquellso que no consideramos\n",
    "test_X_tres_coincidentes = [x for x, y in zip(test_X, considered_index) if y != []]\n",
    "test_y_tres_coincidentes = [x for x, y in zip(test_y, considered_index) if y != []]\n",
    "considered_index_tres_coincidentes = [x for x in considered_index if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.586301Z",
     "iopub.status.idle": "2023-05-31T21:22:29.587156Z",
     "shell.execute_reply": "2023-05-31T21:22:29.586873Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.586841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos KNN con K = 15 y guardamos las distancias para poder hallarlo para k < 15\n",
    "k = 15\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "min_distances_index = []\n",
    "min_distances = []\n",
    "start = time.time()\n",
    "predict_y, mean_error,min_distances_index,min_distances = knn_algorithm(k, train_X, test_X_tres_coincidentes, train_y, test_y_tres_coincidentes,considered_index_tres_coincidentes)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo de ejecución del KNN con tres índices coincidentes = \" + str(end-start))\n",
    "\n",
    "# Con los valores obtenidos, calculamos el error medio de KNN para K de 1 a 15\n",
    "ks = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "predicted_ys, mean_errors = get_multiple_KNN_with_min_distances_and_index(ks, min_distances_index, train_y, test_y_tres_coincidentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.589203Z",
     "iopub.status.idle": "2023-05-31T21:22:29.590208Z",
     "shell.execute_reply": "2023-05-31T21:22:29.589944Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.589915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos en ficheros los valores predichos, los errores medios, las distancias mínimas \n",
    "# y los índices del conjuntio de train de las distancias mínimas\n",
    "KNN_15_tres_coincidentes_predicted_y = open('KNN_15_tres_coincidentes_predicted_y.obj', 'wb')\n",
    "pickle.dump(predicted_ys, KNN_15_tres_coincidentes_predicted_y)\n",
    "KNN_15_tres_coincidentes_predicted_y.close()\n",
    "\n",
    "KNN_15_tres_coincidentes_mean_error = open('KNN_15_tres_coincidentes_mean_error.obj', 'wb')\n",
    "pickle.dump(mean_errors, KNN_15_tres_coincidentes_mean_error)\n",
    "KNN_15_tres_coincidentes_mean_error.close()\n",
    "\n",
    "KNN_15_tres_coincidentes_min_index = open('KNN_15_tres_coincidentes_min_index.obj', 'wb')\n",
    "pickle.dump(min_distances_index, KNN_15_tres_coincidentes_min_index)\n",
    "KNN_15_tres_coincidentes_min_index.close()\n",
    "\n",
    "KNN_15_tres_coincidentes_min_dist = open('KNN_15_tres_coincidentes_min_dist.obj', 'wb')\n",
    "pickle.dump(min_distances, KNN_15_tres_coincidentes_min_dist)\n",
    "KNN_15_tres_coincidentes_min_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:20.934413Z",
     "iopub.status.busy": "2023-06-05T17:30:20.933525Z",
     "iopub.status.idle": "2023-06-05T17:30:20.944182Z",
     "shell.execute_reply": "2023-06-05T17:30:20.942917Z",
     "shell.execute_reply.started": "2023-06-05T17:30:20.934381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para KNN con k = 1 el error medio es 439.95789747402347 metros.\n",
      "Para KNN con k = 2 el error medio es 297.38292749799126 metros.\n",
      "Para KNN con k = 3 el error medio es 248.10734592684057 metros.\n",
      "Para KNN con k = 4 el error medio es 292.5558230091142 metros.\n",
      "Para KNN con k = 5 el error medio es 291.33813233538956 metros.\n",
      "Para KNN con k = 6 el error medio es 316.0838473080919 metros.\n",
      "Para KNN con k = 7 el error medio es 337.7897985598781 metros.\n",
      "Para KNN con k = 8 el error medio es 315.51491575679023 metros.\n",
      "Para KNN con k = 9 el error medio es 319.27293186383133 metros.\n",
      "Para KNN con k = 10 el error medio es 306.1417707860911 metros.\n",
      "Para KNN con k = 11 el error medio es 325.3934182198931 metros.\n",
      "Para KNN con k = 12 el error medio es 319.9654461782252 metros.\n",
      "Para KNN con k = 13 el error medio es 317.5032951726273 metros.\n",
      "Para KNN con k = 14 el error medio es 312.55595261937407 metros.\n",
      "Para KNN con k = 15 el error medio es 298.53296278297415 metros.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "KNN_15_tres_coincidentes_mean_error = open('/kaggle/input/lorawan-output/KNN_15_tres_coincidentes_mean_error.obj', 'rb') \n",
    "mean_errors = pickle.load(KNN_15_tres_coincidentes_mean_error)\n",
    "KNN_15_tres_coincidentes_mean_error.close()\n",
    "\n",
    "for i in range(len(mean_errors)):\n",
    "    print(\"Para KNN con k = \" + str(i+1) + \" el error medio es \" + str(mean_errors[i]) + \" metros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Uso de índices para optimizar: Al menos 2 coincidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.594958Z",
     "iopub.status.idle": "2023-05-31T21:22:29.595901Z",
     "shell.execute_reply": "2023-05-31T21:22:29.595630Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.595592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos, para cada elemento de test, los índices del conjunto de train\n",
    "# que tienen señal en exactamente los mismos índices que el elemento de test\n",
    "considered_index = []\n",
    "considered_index = get_considered_index_at_least_m_equal(2, train_X, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.597994Z",
     "iopub.status.idle": "2023-05-31T21:22:29.598934Z",
     "shell.execute_reply": "2023-05-31T21:22:29.598664Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.598632Z"
    }
   },
   "outputs": [],
   "source": [
    "KNN_test_index_dos_coincidentes = open('KNN_test_index_dos_coincidentes.obj', 'wb')\n",
    "pickle.dump(considered_index, KNN_test_index_dos_coincidentes)\n",
    "KNN_test_index_dos_coincidentes.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.601023Z",
     "iopub.status.idle": "2023-05-31T21:22:29.601869Z",
     "shell.execute_reply": "2023-05-31T21:22:29.601580Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.601528Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(considered_index))\n",
    "n = 0\n",
    "for elem in considered_index:\n",
    "    if elem == []:\n",
    "        n += 1\n",
    "print(\"Hay \" + str(n) + \" elementos del conjunto de test para los que no existe nigún elemento de train con señal en al menos dos mismos índices\")\n",
    "\n",
    "# Creamos las nuevas variables de test para este caso, eliminando aquellso que no consideramos\n",
    "test_X_dos_coincidentes = [x for x, y in zip(test_X, considered_index) if y != []]\n",
    "test_y_dos_coincidentes = [x for x, y in zip(test_y, considered_index) if y != []]\n",
    "considered_index_dos_coincidentes = [x for x in considered_index if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.604011Z",
     "iopub.status.idle": "2023-05-31T21:22:29.605169Z",
     "shell.execute_reply": "2023-05-31T21:22:29.604893Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.604863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos KNN con K = 15 y guardamos las distancias para poder hallarlo para k < 15\n",
    "k = 15\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "min_distances_index = []\n",
    "min_distances = []\n",
    "start = time.time()\n",
    "predict_y, mean_error,min_distances_index,min_distances = knn_algorithm(k, train_X, test_X_dos_coincidentes, train_y, test_y_dos_coincidentes,considered_index_dos_coincidentes)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo de ejecución del KNN con dos índices coincidentes = \" + str(end-start))\n",
    "\n",
    "# Con los valores obtenidos, calculamos el error medio de KNN para K de 1 a 15\n",
    "ks = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "predicted_ys, mean_errors = get_multiple_KNN_with_min_distances_and_index(ks, min_distances_index, train_y, test_y_dos_coincidentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.607100Z",
     "iopub.status.idle": "2023-05-31T21:22:29.607903Z",
     "shell.execute_reply": "2023-05-31T21:22:29.607624Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.607586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos en ficheros los valores predichos, los errores medios, las distancias mínimas \n",
    "# y los índices del conjuntio de train de las distancias mínimas\n",
    "KNN_15_dos_coincidentes_predicted_y = open('KNN_15_dos_coincidentes_predicted_y.obj', 'wb')\n",
    "pickle.dump(predicted_ys, KNN_15_dos_coincidentes_predicted_y)\n",
    "KNN_15_dos_coincidentes_predicted_y.close()\n",
    "\n",
    "KNN_15_dos_coincidentes_mean_error = open('KNN_15_dos_coincidentes_mean_error.obj', 'wb')\n",
    "pickle.dump(mean_errors, KNN_15_dos_coincidentes_mean_error)\n",
    "KNN_15_dos_coincidentes_mean_error.close()\n",
    "\n",
    "KNN_15_dos_coincidentes_min_index = open('KNN_15_dos_coincidentes_min_index.obj', 'wb')\n",
    "pickle.dump(min_distances_index, KNN_15_dos_coincidentes_min_index)\n",
    "KNN_15_dos_coincidentes_min_index.close()\n",
    "\n",
    "KNN_15_dos_coincidentes_min_dist = open('KNN_15_dos_coincidentes_min_dist.obj', 'wb')\n",
    "pickle.dump(min_distances, KNN_15_dos_coincidentes_min_dist)\n",
    "KNN_15_dos_coincidentes_min_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:25.969514Z",
     "iopub.status.busy": "2023-06-05T17:30:25.968925Z",
     "iopub.status.idle": "2023-06-05T17:30:25.978721Z",
     "shell.execute_reply": "2023-06-05T17:30:25.977681Z",
     "shell.execute_reply.started": "2023-06-05T17:30:25.969482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para KNN con k = 1 el error medio es 432.02246622317 metros.\n",
      "Para KNN con k = 2 el error medio es 293.41521187256456 metros.\n",
      "Para KNN con k = 3 el error medio es 245.46220217655608 metros.\n",
      "Para KNN con k = 4 el error medio es 288.46604348731864 metros.\n",
      "Para KNN con k = 5 el error medio es 315.953085641042 metros.\n",
      "Para KNN con k = 6 el error medio es 311.0387996409501 metros.\n",
      "Para KNN con k = 7 el error medio es 329.4350314310435 metros.\n",
      "Para KNN con k = 8 el error medio es 346.7588407609875 metros.\n",
      "Para KNN con k = 9 el error medio es 325.96238469145277 metros.\n",
      "Para KNN con k = 10 el error medio es 365.96681832473485 metros.\n",
      "Para KNN con k = 11 el error medio es 364.45502217886445 metros.\n",
      "Para KNN con k = 12 el error medio es 349.5102156154953 metros.\n",
      "Para KNN con k = 13 el error medio es 362.4640369187582 metros.\n",
      "Para KNN con k = 14 el error medio es 355.1635881188382 metros.\n",
      "Para KNN con k = 15 el error medio es 350.6831811179458 metros.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "KNN_15_dos_coincidentes_mean_error = open('/kaggle/input/lorawan-output/KNN_15_dos_coincidentes_mean_error.obj', 'rb') \n",
    "mean_errors = pickle.load(KNN_15_dos_coincidentes_mean_error)\n",
    "KNN_15_dos_coincidentes_mean_error.close()\n",
    "\n",
    "for i in range(len(mean_errors)):\n",
    "    print(\"Para KNN con k = \" + str(i+1) + \" el error medio es \" + str(mean_errors[i]) + \" metros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Uso de índices para optimizar: Al menos 1 coincidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.612978Z",
     "iopub.status.idle": "2023-05-31T21:22:29.613596Z",
     "shell.execute_reply": "2023-05-31T21:22:29.613308Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.613281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos, para cada elemento de la primera mitad de test test, los índices del conjunto de train\n",
    "# que tienen señal en exactamente los mismos índices que el elemento de test\n",
    "considered_index = []\n",
    "considered_index = get_considered_index_at_least_m_equal(1, train_X, test_X[:12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.615528Z",
     "iopub.status.idle": "2023-05-31T21:22:29.616956Z",
     "shell.execute_reply": "2023-05-31T21:22:29.616668Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.616636Z"
    }
   },
   "outputs": [],
   "source": [
    "KNN_test_index_un_coincidentes_half_1 = open('KNN_test_index_un_coincidentes_half_1.obj', 'wb')\n",
    "pickle.dump(considered_index, KNN_test_index_un_coincidentes_half_1)\n",
    "KNN_test_index_un_coincidentes_half_1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.618624Z",
     "iopub.status.idle": "2023-05-31T21:22:29.619205Z",
     "shell.execute_reply": "2023-05-31T21:22:29.618947Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.618920Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(considered_index))\n",
    "n = 0\n",
    "for elem in considered_index:\n",
    "    if elem == []:\n",
    "        n += 1\n",
    "print(\"Hay \" + str(n) + \" elementos del conjunto de test para los que no existe nigún elemento de train con señal en al menos un mismo índice\")\n",
    "\n",
    "# Creamos las nuevas variables de test para este caso, eliminando aquellso que no consideramos\n",
    "test_X_un_coincidentes = [x for x, y in zip(test_X[:12000], considered_index) if y != []]\n",
    "test_y_un_coincidentes = [x for x, y in zip(test_y[:12000], considered_index) if y != []]\n",
    "considered_index_un_coincidentes = [x for x in considered_index if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.620767Z",
     "iopub.status.idle": "2023-05-31T21:22:29.621330Z",
     "shell.execute_reply": "2023-05-31T21:22:29.621079Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.621052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos KNN con K = 15 y guardamos las distancias para poder hallarlo para k < 15\n",
    "k = 15\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "min_distances_index = []\n",
    "min_distances = []\n",
    "start = time.time()\n",
    "predict_y, mean_error,min_distances_index,min_distances = knn_algorithm(k, train_X, test_X_un_coincidentes, train_y, test_y_un_coincidentes,considered_index_un_coincidentes)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo de ejecución del KNN con un índice coincidente = \" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.622890Z",
     "iopub.status.idle": "2023-05-31T21:22:29.623444Z",
     "shell.execute_reply": "2023-05-31T21:22:29.623198Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.623172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos en ficheros los valores predichos, los errores medios, las distancias mínimas \n",
    "# y los índices del conjuntio de train de las distancias mínimas\n",
    "KNN_15_un_coincidentes_half_1_min_index = open('KNN_15_un_coincidentes_half_1_min_index.obj', 'wb')\n",
    "pickle.dump(min_distances_index, KNN_15_un_coincidentes_half_1_min_index)\n",
    "KNN_15_un_coincidentes_half_1_min_index.close()\n",
    "\n",
    "KNN_15_un_coincidentes_half_1_min_dist = open('KNN_15_un_coincidentes_half_1_min_dist.obj', 'wb')\n",
    "pickle.dump(min_distances, KNN_15_un_coincidentes_half_1_min_dist)\n",
    "KNN_15_un_coincidentes_half_1_min_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.624927Z",
     "iopub.status.idle": "2023-05-31T21:22:29.625492Z",
     "shell.execute_reply": "2023-05-31T21:22:29.625242Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.625215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos, para cada elemento de la primera mitad de test test, los índices del conjunto de train\n",
    "# que tienen señal en exactamente los mismos índices que el elemento de test\n",
    "considered_index = []\n",
    "considered_index = get_considered_index_at_least_m_equal(1, train_X, test_X[12000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.627242Z",
     "iopub.status.idle": "2023-05-31T21:22:29.627839Z",
     "shell.execute_reply": "2023-05-31T21:22:29.627567Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.627519Z"
    }
   },
   "outputs": [],
   "source": [
    "KNN_test_index_un_coincidentes_half_2 = open('KNN_test_index_un_coincidentes_half_2.obj', 'wb')\n",
    "pickle.dump(considered_index, KNN_test_index_un_coincidentes_half_2)\n",
    "KNN_test_index_un_coincidentes_half_2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.634213Z",
     "iopub.status.idle": "2023-05-31T21:22:29.635382Z",
     "shell.execute_reply": "2023-05-31T21:22:29.635091Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.635059Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(considered_index))\n",
    "n = 0\n",
    "for elem in considered_index:\n",
    "    if elem == []:\n",
    "        n += 1\n",
    "print(\"Hay \" + str(n) + \" elementos del conjunto de test para los que no existe nigún elemento de train con señal en al menos un mismo índice\")\n",
    "\n",
    "# Creamos las nuevas variables de test para este caso, eliminando aquellso que no consideramos\n",
    "test_X_un_coincidentes = [x for x, y in zip(test_X[12000:], considered_index) if y != []]\n",
    "test_y_un_coincidentes = [x for x, y in zip(test_y[12000:], considered_index) if y != []]\n",
    "considered_index_un_coincidentes = [x for x in considered_index if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.637233Z",
     "iopub.status.idle": "2023-05-31T21:22:29.638388Z",
     "shell.execute_reply": "2023-05-31T21:22:29.638102Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.638071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos KNN con K = 15 y guardamos las distancias para poder hallarlo para k < 15\n",
    "k = 15\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "min_distances_index = []\n",
    "min_distances = []\n",
    "start = time.time()\n",
    "predict_y, mean_error,min_distances_index,min_distances = knn_algorithm(k, train_X, test_X_un_coincidentes, train_y, test_y_un_coincidentes,considered_index_un_coincidentes)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo de ejecución del KNN con un índice coincidente = \" + str(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.639820Z",
     "iopub.status.idle": "2023-05-31T21:22:29.640833Z",
     "shell.execute_reply": "2023-05-31T21:22:29.640526Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.640497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos en ficheros los valores predichos, los errores medios, las distancias mínimas \n",
    "# y los índices del conjuntio de train de las distancias mínimas\n",
    "KNN_15_un_coincidentes_half_2_min_index = open('KNN_15_un_coincidentes_half_2_min_index.obj', 'wb')\n",
    "pickle.dump(min_distances_index, KNN_15_un_coincidentes_half_2_min_index)\n",
    "KNN_15_un_coincidentes_half_2_min_index.close()\n",
    "\n",
    "KNN_15_un_coincidentes_half_2_min_dist = open('KNN_15_un_coincidentes_half_2_min_dist.obj', 'wb')\n",
    "pickle.dump(min_distances, KNN_15_un_coincidentes_half_2_min_dist)\n",
    "KNN_15_un_coincidentes_half_2_min_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:40.194707Z",
     "iopub.status.busy": "2023-06-05T17:30:40.194352Z",
     "iopub.status.idle": "2023-06-05T17:30:40.833318Z",
     "shell.execute_reply": "2023-06-05T17:30:40.832542Z",
     "shell.execute_reply.started": "2023-06-05T17:30:40.194681Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "KNN_15_un_coincidentes_half_1_min_index = open('/kaggle/input/lorawan-output/KNN_15_un_coincidentes_half_1_min_index.obj', 'rb') \n",
    "min_distances_index_1 = pickle.load(KNN_15_un_coincidentes_half_1_min_index)\n",
    "KNN_15_un_coincidentes_half_2_min_index = open('/kaggle/input/lorawan-output/KNN_15_un_coincidentes_half_2_min_index.obj', 'rb') \n",
    "min_distances_index_2 = pickle.load(KNN_15_un_coincidentes_half_2_min_index)\n",
    "\n",
    "KNN_15_un_coincidentes_half_1_min_dist = open('/kaggle/input/lorawan-output/KNN_15_un_coincidentes_half_1_min_dist.obj', 'rb') \n",
    "min_distances_1 = pickle.load(KNN_15_un_coincidentes_half_1_min_dist)\n",
    "KNN_15_un_coincidentes_half_2_min_dist = open('/kaggle/input/lorawan-output/KNN_15_un_coincidentes_half_2_min_dist.obj', 'rb') \n",
    "min_distances_2 = pickle.load(KNN_15_un_coincidentes_half_2_min_dist)\n",
    "\n",
    "min_distances_index = min_distances_index_1 + min_distances_index_2\n",
    "min_distances = min_distances_1 + min_distances_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:30:42.828017Z",
     "iopub.status.busy": "2023-06-05T17:30:42.826689Z",
     "iopub.status.idle": "2023-06-05T17:30:42.868084Z",
     "shell.execute_reply": "2023-06-05T17:30:42.867346Z",
     "shell.execute_reply.started": "2023-06-05T17:30:42.827958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para KNN con k = 1 el error medio es 432.02246622317 metros.\n",
      "Para KNN con k = 2 el error medio es 293.41521187256456 metros.\n",
      "Para KNN con k = 3 el error medio es 245.46220217655608 metros.\n",
      "Para KNN con k = 4 el error medio es 288.46604348731864 metros.\n",
      "Para KNN con k = 5 el error medio es 315.953085641042 metros.\n",
      "Para KNN con k = 6 el error medio es 311.0387996409501 metros.\n",
      "Para KNN con k = 7 el error medio es 329.4350314310435 metros.\n",
      "Para KNN con k = 8 el error medio es 346.7588407609875 metros.\n",
      "Para KNN con k = 9 el error medio es 325.96238469145277 metros.\n",
      "Para KNN con k = 10 el error medio es 365.96681832473485 metros.\n",
      "Para KNN con k = 11 el error medio es 364.45502217886445 metros.\n",
      "Para KNN con k = 12 el error medio es 349.5102156154953 metros.\n",
      "Para KNN con k = 13 el error medio es 362.4640369187582 metros.\n",
      "Para KNN con k = 14 el error medio es 355.1635881188382 metros.\n",
      "Para KNN con k = 15 el error medio es 350.6831811179458 metros.\n"
     ]
    }
   ],
   "source": [
    "# Con los valores obtenidos, calculamos el error medio de KNN para K de 1 a 15\n",
    "ks = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "predicted_ys, mean_errors = get_multiple_KNN_with_min_distances_and_index(ks, min_distances_index, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-31T21:22:29.647412Z",
     "iopub.status.idle": "2023-05-31T21:22:29.648623Z",
     "shell.execute_reply": "2023-05-31T21:22:29.648342Z",
     "shell.execute_reply.started": "2023-05-31T21:22:29.648311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Guardamos en ficheros los valores predichos, los errores medios, las distancias mínimas \n",
    "# y los índices del conjuntio de train de las distancias mínimas\n",
    "KNN_15_un_coincidentes_predicted_y = open('KNN_15_un_coincidentes_predicted_y.obj', 'wb')\n",
    "pickle.dump(predicted_ys, KNN_15_un_coincidentes_predicted_y)\n",
    "KNN_15_un_coincidentes_predicted_y.close()\n",
    "\n",
    "KNN_15_un_coincidentes_mean_error = open('KNN_15_un_coincidentes_mean_error.obj', 'wb')\n",
    "pickle.dump(mean_errors, KNN_15_un_coincidentes_mean_error)\n",
    "KNN_15_un_coincidentes_mean_error.close()\n",
    "\n",
    "KNN_15_un_coincidentes_min_index = open('KNN_15_un_coincidentes_min_index.obj', 'wb')\n",
    "pickle.dump(min_distances_index, KNN_15_un_coincidentes_min_index)\n",
    "KNN_15_un_coincidentes_min_index.close()\n",
    "\n",
    "KNN_15_un_coincidentes_min_dist = open('KNN_15_un_coincidentes_min_dist.obj', 'wb')\n",
    "pickle.dump(min_distances, KNN_15_un_coincidentes_min_dist)\n",
    "KNN_15_un_coincidentes_min_dist.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "KNN_15_un_coincidentes_mean_error = open('/kaggle/input/lorawan-output/KNN_15_un_coincidentes_mean_error.obj', 'rb') \n",
    "mean_errors = pickle.load(KNN_15_un_coincidentes_mean_error)\n",
    "KNN_15_un_coincidentes_mean_error.close()\n",
    "\n",
    "for i in range(len(mean_errors)):\n",
    "    print(\"Para KNN con k = \" + str(i+1) + \" el error medio es \" + str(mean_errors[i]) + \" metros.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Distancia sorensen con al menos 3 coincidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:33:29.931706Z",
     "iopub.status.busy": "2023-06-05T17:33:29.931115Z",
     "iopub.status.idle": "2023-06-05T17:33:29.937816Z",
     "shell.execute_reply": "2023-06-05T17:33:29.936064Z",
     "shell.execute_reply.started": "2023-06-05T17:33:29.931658Z"
    }
   },
   "outputs": [],
   "source": [
    "def sorensen_distance(a,b):\n",
    "    sum_up = 0\n",
    "    sum_down = 0\n",
    "    for i in range(len(a)):\n",
    "        sum_up += abs(a[i]-b[i])\n",
    "        sum_down += (a[i] + b[i])\n",
    "    return sum_up / sum_down        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:33:32.388098Z",
     "iopub.status.busy": "2023-06-05T17:33:32.387723Z",
     "iopub.status.idle": "2023-06-05T17:33:34.244805Z",
     "shell.execute_reply": "2023-06-05T17:33:34.243318Z",
     "shell.execute_reply.started": "2023-06-05T17:33:32.388070Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "filehandler_KNN_test_index_tres_coincidentes = open('/kaggle/input/lorawan-output/KNN_test_index_tres_coincidentes.obj', 'rb') \n",
    "considered_index = pickle.load(filehandler_KNN_test_index_tres_coincidentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:33:35.710282Z",
     "iopub.status.busy": "2023-06-05T17:33:35.709877Z",
     "iopub.status.idle": "2023-06-05T17:33:35.734719Z",
     "shell.execute_reply": "2023-06-05T17:33:35.733143Z",
     "shell.execute_reply.started": "2023-06-05T17:33:35.710253Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos las nuevas variables de test para este caso, eliminando aquellso que no consideramos\n",
    "test_X_tres_coincidentes = [x for x, y in zip(test_X, considered_index) if y != []]\n",
    "test_y_tres_coincidentes = [x for x, y in zip(test_y, considered_index) if y != []]\n",
    "considered_index_tres_coincidentes = [x for x in considered_index if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:33:41.067471Z",
     "iopub.status.busy": "2023-06-05T17:33:41.067033Z",
     "iopub.status.idle": "2023-06-05T17:40:36.117594Z",
     "shell.execute_reply": "2023-06-05T17:40:36.115812Z",
     "shell.execute_reply.started": "2023-06-05T17:33:41.067444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución del KNN con tres índices coincidentes = 415.0178163051605\n",
      "Para KNN con k = 1 el error medio es 439.95789747437686 metros.\n",
      "Para KNN con k = 2 el error medio es 402.2537613181579 metros.\n",
      "Para KNN con k = 3 el error medio es 558.5848935820092 metros.\n",
      "Para KNN con k = 4 el error medio es 523.7170612750031 metros.\n",
      "Para KNN con k = 5 el error medio es 733.1132765194125 metros.\n",
      "Para KNN con k = 6 el error medio es 678.0232771036864 metros.\n",
      "Para KNN con k = 7 el error medio es 630.649959926534 metros.\n",
      "Para KNN con k = 8 el error medio es 568.0237971183449 metros.\n",
      "Para KNN con k = 9 el error medio es 545.1256231623041 metros.\n",
      "Para KNN con k = 10 el error medio es 509.40919295475186 metros.\n",
      "Para KNN con k = 11 el error medio es 599.4754365342313 metros.\n",
      "Para KNN con k = 12 el error medio es 590.986985199362 metros.\n",
      "Para KNN con k = 13 el error medio es 578.8347327103222 metros.\n",
      "Para KNN con k = 14 el error medio es 648.3147794687055 metros.\n",
      "Para KNN con k = 15 el error medio es 610.2732229472011 metros.\n"
     ]
    }
   ],
   "source": [
    "# Calculamos KNN con K = 15 y guardamos las distancias para poder hallarlo para k < 15\n",
    "k = 15\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "min_distances_index = []\n",
    "min_distances = []\n",
    "start = time.time()\n",
    "predict_y, mean_error,min_distances_index,min_distances = knn_algorithm(k, train_X, test_X_tres_coincidentes, train_y, test_y_tres_coincidentes,considered_index_tres_coincidentes, 'sorensen')\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo de ejecución del KNN con tres índices coincidentes = \" + str(end-start))\n",
    "\n",
    "# Con los valores obtenidos, calculamos el error medio de KNN para K de 1 a 15\n",
    "ks = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "predicted_ys, mean_errors = get_multiple_KNN_with_min_distances_and_index(ks, min_distances_index, train_y, test_y_tres_coincidentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Distancia Manhattan con al menos 3 coincidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:40:36.119857Z",
     "iopub.status.busy": "2023-06-05T17:40:36.119540Z",
     "iopub.status.idle": "2023-06-05T17:40:36.125201Z",
     "shell.execute_reply": "2023-06-05T17:40:36.123792Z",
     "shell.execute_reply.started": "2023-06-05T17:40:36.119831Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cityblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:40:36.127026Z",
     "iopub.status.busy": "2023-06-05T17:40:36.126663Z",
     "iopub.status.idle": "2023-06-05T17:40:37.261397Z",
     "shell.execute_reply": "2023-06-05T17:40:37.260544Z",
     "shell.execute_reply.started": "2023-06-05T17:40:36.126997Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "filehandler_KNN_test_index_tres_coincidentes = open('/kaggle/input/lorawan-output/KNN_test_index_tres_coincidentes.obj', 'rb') \n",
    "considered_index = pickle.load(filehandler_KNN_test_index_tres_coincidentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:40:37.264089Z",
     "iopub.status.busy": "2023-06-05T17:40:37.263310Z",
     "iopub.status.idle": "2023-06-05T17:40:37.452828Z",
     "shell.execute_reply": "2023-06-05T17:40:37.452022Z",
     "shell.execute_reply.started": "2023-06-05T17:40:37.264034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos las nuevas variables de test para este caso, eliminando aquellso que no consideramos\n",
    "test_X_tres_coincidentes = [x for x, y in zip(test_X, considered_index) if y != []]\n",
    "test_y_tres_coincidentes = [x for x, y in zip(test_y, considered_index) if y != []]\n",
    "considered_index_tres_coincidentes = [x for x in considered_index if x != []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:40:37.454537Z",
     "iopub.status.busy": "2023-06-05T17:40:37.454207Z",
     "iopub.status.idle": "2023-06-05T17:46:06.652080Z",
     "shell.execute_reply": "2023-06-05T17:46:06.651084Z",
     "shell.execute_reply.started": "2023-06-05T17:40:37.454510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución del KNN con tres índices coincidentes = 329.1016616821289\n",
      "Para KNN con k = 1 el error medio es 439.95789747402347 metros.\n",
      "Para KNN con k = 2 el error medio es 284.0567792958599 metros.\n",
      "Para KNN con k = 3 el error medio es 234.60334226527178 metros.\n",
      "Para KNN con k = 4 el error medio es 283.19808537484755 metros.\n",
      "Para KNN con k = 5 el error medio es 283.8519422279762 metros.\n",
      "Para KNN con k = 6 el error medio es 306.9846496728931 metros.\n",
      "Para KNN con k = 7 el error medio es 328.769711626514 metros.\n",
      "Para KNN con k = 8 el error medio es 304.9154460085299 metros.\n",
      "Para KNN con k = 9 el error medio es 304.2357266892903 metros.\n",
      "Para KNN con k = 10 el error medio es 292.60828612911024 metros.\n",
      "Para KNN con k = 11 el error medio es 313.0902503499105 metros.\n",
      "Para KNN con k = 12 el error medio es 315.21753696228933 metros.\n",
      "Para KNN con k = 13 el error medio es 308.4692069143178 metros.\n",
      "Para KNN con k = 14 el error medio es 304.16715637951523 metros.\n",
      "Para KNN con k = 15 el error medio es 292.62276562746064 metros.\n"
     ]
    }
   ],
   "source": [
    "# Calculamos KNN con K = 15 y guardamos las distancias para poder hallarlo para k < 15\n",
    "k = 15\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "min_distances_index = []\n",
    "min_distances = []\n",
    "start = time.time()\n",
    "predict_y, mean_error,min_distances_index,min_distances = knn_algorithm(k, train_X, test_X_tres_coincidentes, train_y, test_y_tres_coincidentes,considered_index_tres_coincidentes, 'manhattan')\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tiempo de ejecución del KNN con tres índices coincidentes = \" + str(end-start))\n",
    "\n",
    "# Con los valores obtenidos, calculamos el error medio de KNN para K de 1 a 15\n",
    "ks = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "predicted_ys = []\n",
    "mean_errors = []\n",
    "predicted_ys, mean_errors = get_multiple_KNN_with_min_distances_and_index(ks, min_distances_index, train_y, test_y_tres_coincidentes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:46:06.654932Z",
     "iopub.status.busy": "2023-06-05T17:46:06.653856Z",
     "iopub.status.idle": "2023-06-05T17:46:17.889036Z",
     "shell.execute_reply": "2023-06-05T17:46:17.887654Z",
     "shell.execute_reply.started": "2023-06-05T17:46:06.654901Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Definir una función para crear y entrenar el modelo\n",
    "def train_model(learning_rate, num_neuronas, dropout, train_X, test_X, train_y, test_y, loss_function = 'mse'):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(num_neuronas, activation='relu', input_shape=(68,)))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(num_neuronas, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(num_neuronas, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(num_neuronas, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(2))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss_function)\n",
    "\n",
    "    model.fit(train_X, train_y, epochs=500, validation_data=(test_X, test_y), verbose=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo con learning_rate=0.001, num_neuronas=32, dropout_valor=0.2\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 1971.6104452864638 metros\n",
      "Entrenando modelo con learning_rate=0.001, num_neuronas=32, dropout_valor=0.4\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 1683.8604890952467 metros\n",
      "Entrenando modelo con learning_rate=0.001, num_neuronas=32, dropout_valor=0.6\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 1907.4081210573868 metros\n",
      "Entrenando modelo con learning_rate=0.001, num_neuronas=128, dropout_valor=0.2\n",
      "773/773 [==============================] - 1s 2ms/step\n",
      "El error es de 1384591.5104975754 metros\n",
      "Entrenando modelo con learning_rate=0.001, num_neuronas=128, dropout_valor=0.4\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 12395.623357161723 metros\n",
      "Entrenando modelo con learning_rate=0.001, num_neuronas=128, dropout_valor=0.6\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 3770.454578244374 metros\n",
      "Entrenando modelo con learning_rate=0.01, num_neuronas=32, dropout_valor=0.2\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 37401.70306992816 metros\n",
      "Entrenando modelo con learning_rate=0.01, num_neuronas=32, dropout_valor=0.4\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 2890.033666461316 metros\n",
      "Entrenando modelo con learning_rate=0.01, num_neuronas=32, dropout_valor=0.6\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 3158.5655440578134 metros\n",
      "Entrenando modelo con learning_rate=0.01, num_neuronas=128, dropout_valor=0.2\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 3271.322940228042 metros\n",
      "Entrenando modelo con learning_rate=0.01, num_neuronas=128, dropout_valor=0.4\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 1786.2437297498122 metros\n",
      "Entrenando modelo con learning_rate=0.01, num_neuronas=128, dropout_valor=0.6\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 3417.176806859702 metros\n",
      "Entrenando modelo con learning_rate=0.1, num_neuronas=32, dropout_valor=0.2\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 2342.2342931732323 metros\n",
      "Entrenando modelo con learning_rate=0.1, num_neuronas=32, dropout_valor=0.4\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 2418.958646049293 metros\n",
      "Entrenando modelo con learning_rate=0.1, num_neuronas=32, dropout_valor=0.6\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 1692.6118307472148 metros\n",
      "Entrenando modelo con learning_rate=0.1, num_neuronas=128, dropout_valor=0.2\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 1833.7120846951157 metros\n",
      "Entrenando modelo con learning_rate=0.1, num_neuronas=128, dropout_valor=0.4\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 2129.868568520109 metros\n",
      "Entrenando modelo con learning_rate=0.1, num_neuronas=128, dropout_valor=0.6\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 1724.360072036739 metros \n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "num_neuronas_list = [32, 128]\n",
    "dropout_valores = [0.2, 0.4, 0.6]\n",
    "\n",
    "best_model = None\n",
    "best_error = None\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for num_neuronas in num_neuronas_list:\n",
    "        for dropout_valor in dropout_valores:\n",
    "            print(f\"Entrenando modelo con learning_rate={learning_rate}, num_neuronas={num_neuronas}, dropout_valor={dropout_valor}\")\n",
    "            model = train_model(learning_rate, num_neuronas, dropout_valor, train_X, test_X, train_y, test_y)\n",
    "            predict_y = model.predict(test_X)\n",
    "            \n",
    "            distances_test_predict = []\n",
    "            for i in range(len(predict_y)):\n",
    "                distances_test_predict.append(haversine(test_y[i][0],predict_y[i][0],test_y[i][1],predict_y[i][1]))\n",
    "\n",
    "            # Calculamos el error medio\n",
    "            print(\"El error es de \" + str(np.mean(distances_test_predict)) + \" metros\")\n",
    "            \n",
    "            model.save(\"model_lr\"+str(learning_rate)+\"_nn\"+ str(num_neuronas)+\"_dr\"+str(dropout_valor)+\".h5\")\n",
    "\n",
    "            if best_error is None or np.mean(distances_test_predict) < best_error:\n",
    "                best_error = np.mean(distances_test_predict)\n",
    "                best_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Función de pérdida: función Haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:51:44.665920Z",
     "iopub.status.busy": "2023-06-05T17:51:44.664900Z",
     "iopub.status.idle": "2023-06-05T17:51:44.672643Z",
     "shell.execute_reply": "2023-06-05T17:51:44.671413Z",
     "shell.execute_reply.started": "2023-06-05T17:51:44.665884Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def degrees_to_radians(deg):\n",
    "    return deg * 0.017453292519943295\n",
    "\n",
    "def loss_haversine(observation, prediction):    \n",
    "    obv_rad = K.map_fn(degrees_to_radians, observation)\n",
    "    prev_rad = K.map_fn(degrees_to_radians, prediction)\n",
    "\n",
    "    dlon_dlat = obv_rad - prev_rad \n",
    "    v = dlon_dlat / 2\n",
    "    v = tf.sin(v)\n",
    "    v = v**2\n",
    "\n",
    "    a = v[:,0] + K.cos(obv_rad[:,0]) * K.cos(prev_rad[:,0]) * v[:,1] \n",
    "\n",
    "    c = K.sqrt(a)\n",
    "    c = 2* tf.asin(c)\n",
    "    c = c*6378.1 # radio de la tierra en metros\n",
    "\n",
    "    final = tf.reduce_sum(c)\n",
    "\n",
    "    return final*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:52:16.698207Z",
     "iopub.status.busy": "2023-06-05T17:52:16.697838Z",
     "iopub.status.idle": "2023-06-05T17:52:16.704364Z",
     "shell.execute_reply": "2023-06-05T17:52:16.703223Z",
     "shell.execute_reply.started": "2023-06-05T17:52:16.698177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3089/3089 [==============================] - 16s 5ms/step - loss: 423744.3750 - val_loss: 84797400.0000\n",
      "773/773 [==============================] - 1s 1ms/step\n",
      "El error es de 2643059.4465170344 metros\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el mejor modelo con la función de pérdida loss_haversine\n",
    "\n",
    "model = train_model(0.001, 32, 0.4, train_X, test_X, train_y, test_y, loss_haversine)\n",
    "predict_y = model.predict(test_X)\n",
    "\n",
    "distances_test_predict = []\n",
    "for i in range(len(predict_y)):\n",
    "    distances_test_predict.append(haversine(test_y[i][0],predict_y[i][0],test_y[i][1],predict_y[i][1]))\n",
    "\n",
    "# Calculamos el error medio\n",
    "print(\"El error es de \" + str(np.mean(distances_test_predict)) + \" metros\")\n",
    "\n",
    "model.save(\"model_haversine.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:52:38.461207Z",
     "iopub.status.busy": "2023-06-05T17:52:38.460005Z",
     "iopub.status.idle": "2023-06-05T17:52:38.887271Z",
     "shell.execute_reply": "2023-06-05T17:52:38.886545Z",
     "shell.execute_reply.started": "2023-06-05T17:52:38.461173Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def random_forest(n_estimators, max_depth, min_samples_split, train_X, train_y):\n",
    "    # Crear y entrenar el modelo de Random Forest\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "    model.fit(train_X, train_y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-05T17:54:40.205511Z",
     "iopub.status.busy": "2023-06-05T17:54:40.205088Z",
     "iopub.status.idle": "2023-06-05T18:13:22.904425Z",
     "shell.execute_reply": "2023-06-05T18:13:22.903512Z",
     "shell.execute_reply.started": "2023-06-05T17:54:40.205482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo con n_estimators=50, max_depth=None, min_samples_split=2\n",
      "El error es de 489.6140779668307 metros\n",
      "Entrenando modelo con n_estimators=50, max_depth=None, min_samples_split=5\n",
      "El error es de 479.0538700815534 metros\n",
      "Entrenando modelo con n_estimators=50, max_depth=None, min_samples_split=10\n",
      "El error es de 471.7883495723622 metros\n",
      "Entrenando modelo con n_estimators=50, max_depth=5, min_samples_split=2\n",
      "El error es de 965.7151393203206 metros\n",
      "Entrenando modelo con n_estimators=50, max_depth=5, min_samples_split=5\n",
      "El error es de 969.0437630881667 metros\n",
      "Entrenando modelo con n_estimators=50, max_depth=5, min_samples_split=10\n",
      "El error es de 965.5975559592532 metros\n",
      "Entrenando modelo con n_estimators=50, max_depth=10, min_samples_split=2\n",
      "El error es de 648.7532987656006 metros\n",
      "Entrenando modelo con n_estimators=50, max_depth=10, min_samples_split=5\n",
      "El error es de 650.3392546416533 metros\n",
      "Entrenando modelo con n_estimators=50, max_depth=10, min_samples_split=10\n",
      "El error es de 651.0806081644256 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=None, min_samples_split=2\n",
      "El error es de 487.72056879127757 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=None, min_samples_split=5\n",
      "El error es de 477.16376224185376 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=None, min_samples_split=10\n",
      "El error es de 470.74954306310184 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=5, min_samples_split=2\n",
      "El error es de 964.0022293537745 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=5, min_samples_split=5\n",
      "El error es de 966.0447147430019 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=5, min_samples_split=10\n",
      "El error es de 966.6183901279783 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=10, min_samples_split=2\n",
      "El error es de 647.6408575791814 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=10, min_samples_split=5\n",
      "El error es de 645.7327666345836 metros\n",
      "Entrenando modelo con n_estimators=100, max_depth=10, min_samples_split=10\n",
      "El error es de 648.9250180184645 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=None, min_samples_split=2\n",
      "El error es de 487.1236194983572 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=None, min_samples_split=5\n",
      "El error es de 476.79476044438763 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=None, min_samples_split=10\n",
      "El error es de 470.20708796285334 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=5, min_samples_split=2\n",
      "El error es de 966.7943476780192 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=5, min_samples_split=5\n",
      "El error es de 965.6357205884145 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=5, min_samples_split=10\n",
      "El error es de 966.8265102099747 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=10, min_samples_split=2\n",
      "El error es de 649.2625328913496 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=10, min_samples_split=5\n",
      "El error es de 649.5386250263851 metros\n",
      "Entrenando modelo con n_estimators=200, max_depth=10, min_samples_split=10\n",
      "El error es de 649.5565599268474 metros\n"
     ]
    }
   ],
   "source": [
    "# Probar diferentes combinaciones de hiperparámetros\n",
    "n_estimators = [50, 100, 200]\n",
    "max_depth = [None, 5, 10]\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "best_model = None\n",
    "best_error = None\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    for max_depth_actual in max_depth:\n",
    "        for min_samples_split_actual in min_samples_split:\n",
    "            print(f\"Entrenando modelo con n_estimators={n_estimator}, max_depth={max_depth_actual}, min_samples_split={min_samples_split_actual}\")\n",
    "            model = random_forest(n_estimator, max_depth_actual, min_samples_split_actual, train_X, train_y)\n",
    "            predict_y = model.predict(test_X)\n",
    "            \n",
    "            distances_test_predict = []\n",
    "            for i in range(len(predict_y)):\n",
    "                distances_test_predict.append(haversine(test_y[i][0],predict_y[i][0],test_y[i][1],predict_y[i][1]))\n",
    "\n",
    "            # Calculamos el error medio\n",
    "            print(\"El error es de \" + str(np.mean(distances_test_predict)) + \" metros\")\n",
    "\n",
    "            if best_error is None or np.mean(distances_test_predict) < best_error:\n",
    "                best_error = np.mean(distances_test_predict)\n",
    "                best_model = model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
